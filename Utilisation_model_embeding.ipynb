{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import keras.datasets.imdb as imdb\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import json,re\n",
    "import numpy as np\n",
    "\n",
    "import fidle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size           = 10000\n",
    "review_len           = 256\n",
    "\n",
    "saved_models         = 'C:/models_embeding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commaitaire dont on veut prédire le sentiment\n",
    "reviews = [ \"This film is particularly nice, a must see.\",\n",
    "             \"This film is a great classic that cannot be ignored.\",\n",
    "             \"I don't remember ever having seen such a movie...\",\n",
    "             \"This movie is just abominable and doesn't deserve to be seen!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_char = 1      # Start of a sequence (padding is 0)\n",
    "oov_char   = 2      # Out-of-vocabulary\n",
    "index_from = 3      # First word id\n",
    "\n",
    "# ---- Retrieve dictionary {word:index}, and encode it in ascii\n",
    "#      Shift the dictionary from +3\n",
    "#      Add <pad>, <start> and <unknown> tags\n",
    "#      Create a reverse dictionary : {index:word}\n",
    "#\n",
    "word_index = imdb.get_word_index()\n",
    "word_index = {w:(i+index_from) for w,i in word_index.items()}\n",
    "word_index.update( {'<pad>':0, '<start>':1, '<unknown>':2, '<undef>':3,} )\n",
    "index_word = {index:word for word,index in word_index.items()} \n",
    "\n",
    "# ---- A nice function to transpose :\n",
    "#\n",
    "def dataset2text(review):\n",
    "    return ' '.join([index_word.get(i, '?') for i in review])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nétoyage (on enlève les points), indexation et padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 is 'start' and 2 is 'unknow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words are : 1 2 22 9 572 2 6 215 2 \n",
      "Words are : 1 2 22 9 6 87 356 15 566 30 2 \n",
      "Words are : 1 2 92 377 126 260 110 141 6 2 \n",
      "Words are : 1 2 20 9 43 2 5 152 1833 8 30 2 \n"
     ]
    }
   ],
   "source": [
    "start_char = 1      # Start of a sequence (padding is 0)\n",
    "oov_char   = 2      # Out-of-vocabulary\n",
    "index_from = 3      # First word id\n",
    "\n",
    "nb_reviews = len(reviews)\n",
    "x_data     = []\n",
    "\n",
    "# ---- For all reviews\n",
    "for review in reviews:\n",
    "    print('Words are : ', end='')\n",
    "    # ---- First index must be <start>\n",
    "    index_review=[start_char]\n",
    "    print(f'{start_char} ', end='')\n",
    "    # ---- For all words\n",
    "    for w in review.split(' '):\n",
    "        # ---- Clean it\n",
    "        w_clean = re.sub(r\"[^a-zA-Z0-9]\", \"\", w)#Suppression des caractères alpha numéric\n",
    "        # ---- Not empty ?\n",
    "        if len(w_clean)>0:\n",
    "            # ---- Get the index - must be inside dict or is out of vocab (oov)\n",
    "            w_index = word_index.get(w, oov_char)\n",
    "            if w_index>vocab_size : w_index=oov_char\n",
    "            # ---- Add the index if < vocab_size\n",
    "            index_review.append(w_index)\n",
    "            print(f'{w_index} ', end='')\n",
    "    # ---- Add the indexed review\n",
    "    x_data.append(index_review)\n",
    "    print()\n",
    "\n",
    "# ---- Padding\n",
    "x_data = keras.preprocessing.sequence.pad_sequences(x_data, value   = 0, padding = 'post', maxlen  = review_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text review 0  : This film is particularly nice, a must see.\n",
      "tokens vector  : [1, 2, 22, 9, 572, 2, 6, 215, 2, 0, 0, 0, 0, 0] (...)\n",
      "Translation    : <start> <unknown> film is particularly <unknown> a must <unknown> <pad> <pad> <pad> <pad> <pad> (...)\n",
      "\n",
      "Text review 1  : This film is a great classic that cannot be ignored.\n",
      "tokens vector  : [1, 2, 22, 9, 6, 87, 356, 15, 566, 30, 2, 0, 0, 0, 0, 0] (...)\n",
      "Translation    : <start> <unknown> film is a great classic that cannot be <unknown> <pad> <pad> <pad> <pad> <pad> (...)\n",
      "\n",
      "Text review 2  : I don't remember ever having seen such a movie...\n",
      "tokens vector  : [1, 2, 92, 377, 126, 260, 110, 141, 6, 2, 0, 0, 0, 0, 0] (...)\n",
      "Translation    : <start> <unknown> don't remember ever having seen such a <unknown> <pad> <pad> <pad> <pad> <pad> (...)\n",
      "\n",
      "Text review 3  : This movie is just abominable and doesn't deserve to be seen!\n",
      "tokens vector  : [1, 2, 20, 9, 43, 2, 5, 152, 1833, 8, 30, 2, 0, 0, 0, 0, 0] (...)\n",
      "Translation    : <start> <unknown> movie is just <unknown> and doesn't deserve to be <unknown> <pad> <pad> <pad> <pad> <pad> (...)\n"
     ]
    }
   ],
   "source": [
    "def translate(x):\n",
    "    return ' '.join( [index_word.get(i,'?') for i in x] )\n",
    "\n",
    "for i in range(nb_reviews):\n",
    "    imax=np.where(x_data[i]==0)[0][0]+5\n",
    "    print(f'\\nText review {i}  :',    reviews[i])\n",
    "    print(f'tokens vector  :', list(x_data[i][:imax]), '(...)')\n",
    "    print('Translation    :', translate(x_data[i][:imax]), '(...)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appel du modèle et prévision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This film is particularly nice, a must see.                            => 0.54 - POSITIVE :-)\n",
      "This film is a great classic that cannot be ignored.                   => 0.73 - POSITIVE :-)\n",
      "I don't remember ever having seen such a movie...                      => 0.54 - POSITIVE :-)\n",
      "This movie is just abominable and doesn't deserve to be seen!          => 0.34 - NEGATIVE :-(\n"
     ]
    }
   ],
   "source": [
    "#Chargement du modèle\n",
    "model = keras.models.load_model('models_embeding/best_model.keras')\n",
    "\n",
    "#Prédiction\n",
    "y_pred   = model.predict(x_data, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "for i,review in enumerate(reviews):\n",
    "    rate    = y_pred[i][0]\n",
    "    opinion =  'NEGATIVE :-(' if rate<0.5 else 'POSITIVE :-)'    \n",
    "    print(f'{review:<70} => {rate:.2f} - {opinion}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apprentissage_env",
   "language": "python",
   "name": "apprentissage_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
